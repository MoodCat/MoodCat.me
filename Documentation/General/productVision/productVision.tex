\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{siunitx}

\begin{document}

\title{Product Vision\\
	\begin{small}
	The why, who and what
	\end{small}
}
% Question: should this be our names or organization name?
\author{MoodCat.me}
\maketitle

\subsection*{Preface}

When people want to party they loud bass-heavy hype music.
When people feel down they want to listen to slower emotional music.
When people feel sleepy they want to listen to calm music.
What music people listen is based on their mood, there's no doubt about that.

There is, however, another side to this relationship between mood and music.
Not only do people want to listen music related to the mood they're in,
music can actively change the mood of the listener.
When people listen to loud bass-heavy hype music, people do get hyped,
people do get sad when listening to sad music,
sleepy music makes people sleepy.

Our goal is to use this bidirectional relationship between mood and music,
combine it with a music recommendation system and make a music service
that will influence and be influenced by the listener's mood over time.
This is our main focus point.

Besides this we're going to add a social component to listening mood based music.
It doesn't matter which genre, which mood, listening music is always more powerful if you can do it together.
We want to make a music service that connects people that are in the same mood, and make them enjoy their moods together.
Users of our music service will be able to join a room based on a chosen mood and chat and listen music along with other people with the same mood.

The general idea of rooms is that the room's mood changes over time, new songs will be put forward programatically. Happy rooms might slowly 
transition to relaxed rooms or maybe move towards louder music. Listeners will provide feedback on the change of music through like and dislike
buttons and together this will be a concretion of the mood/music relation.

Our service will is all about mood combined with social interaction through the Internet. Cats rule the internet like this MoodCat has been born.

\section{Why should we build MoodCat?}
Various competitors provide a system that can offer users popular songs or songs that are similar to songs the user already listened to.
These recommendations mostly consist of songs that are popular or users with simmilar preferences listened to.
This leaves a huge amount of music produced by a lot of artists undiscovered.

Secondly, most music platforms do not offer user interaction.
Some competitors offer users rooms to socialize while experiencing songs.
An example is Plug DJ \cite{PlugDJ} where users can create a room and listeners can suggest Youtube-songs\cite{Youtube} for the playlist.
Such a playlist has to be maintained in order to keep running and therefore does not suit the listeners that want to listen on their own.
Furthermore, it has to be moderated to prevent unwanted suggestions that might not be interesting for the listeners.

\bigskip 

Users want to discover music and have social interaction.
MoodCat allows users (and friends!) to unite in rooms, and listen to and discuss music together.
Hereby we apply a successful feature from the live video/gaming streaming industry (for example TwitchTV \cite{Twitch}) to the music industry.
Music rooms never fall silent, instead they are continuously filled with relevant music that fits the mood of the listeners in the room.

\section{What is the target audience of MoodCat?}
Our target audience consists of (but not limiting to) the following persons:

\begin{enumerate}
\item Everyone who wants to listen to music without the hassle of searching suitable songs for both their musical preference and current mood.

\item Everyone who wants to discover and listen to songs they have not heard yet.

\item Everyone who wants to listen to and experience songs and share this experience with fellow listeners in the same online room.

\item Everyone who wants to listen at any time on the day, no matter how many users are currently online.
\end{enumerate}

\section{What are the selling points of MoodCat?}
MoodCat has several selling points that would make it unique in the current music market.

\begin{enumerate}
\item MoodCat is self-maintaining, which makes it possible to handle audience sizes from one to one thousand.
This makes it possible to use the service no matter how many other users are currently online.

\item MoodCat offers users both to experience solely or communicate with fellow music listeners.

\item The system already works without user input as specific interpretation of audio features allow us to find similar songs.

\item The system is able to offer relevant songs using the specified current mood of the user.

\item With MoodCat unknown or lesser known artists have equal chances to let their songs be played.
This is a result of the system choosing songs based on features and is therefore unbiased regarding play counts.

\item MoodCat can determine mood trends of a long-term user and can adjust the room-ordering mechanism accordingly.
Therefore long-term users are served more suitable rooms which increases their overall satisfaction.

\item MoodCat can suggest users who are repeatedly not satisfied with the songs played in a room, a different and more suitable room.
\end{enumerate}

\section{Which components should MoodCat have?}
MoodCat will be developed as three separate componentents: the frontend, the backend and a special music matching algorithm.

\begin{enumerate}
\item The frontend will be the visible part for the listener.
After logging in to our services, the user will be able to select his mood and based on that MoodCat will provide several music listening rooms.
In these rooms the user can interact with other listeners through the chat while listening to the music.

\item The backend keeps track of which rooms are active and what song is currently played in the room.
Furthermore, the backend is responsible for transmitting the chat messages between the users in the room.

\item The music matching algorithm is used to compare and match moods of songs and chatrooms.
It has two roles: list the room suggestions for a user and provide the next song to be played for a room.
\end{enumerate}

\newpage

\subsection{Frontend}

The MoodCat frontend will be web-based.
This allows us to support all modern devices which enables a large target audience.
We will develop the frontend using modern techniques as HTML5\cite{HTML}, CSS3\cite{CSS} and AngularJS\cite{AngularJS}.
Users can login using their Soundcloud account.
This allows us to integrate with the Soundcloud platform and prevents having to register for our services first.

\subsection{Backend}

The MoodCat backend will be a RESTful\cite{rest} API written in Java using JAX-RS. It will be backed by a relational (PostgreSQL) database. The backend connects the frontend to the music matching algorithm.

\subsection{Music matching algorithm}

The Music matching algorithm determines and compares moods for songs, rooms and users.
Moodcat will be developed around a learning algorithm.
This means that Moodcat will improve over time.
Default values will be determined by examining the audio features provided by our data set.
Then, through a system of user votes, the system will learn and improve over time.

We discovered that moods and emotions can be mapped to a valence/arousal space (see figure \ref{fig:avgraph}).
% This graph has been of interest for some scientifical papers \cite{Kosina} \cite{McVicar}.
%     The references are unrelated. Also this sentence seems a bit unnecessary in the story

\begin{figure}[h]
\center
\includegraphics[scale=0.75]{../avgraph.jpg}
\caption{The valance/arousal graph \cite{Book}}
\endcenter
\label{fig:avgraph}

\end{figure}

Arousal and valence are physiological terms.
Arousal means how calm or excited you are.
Valence is the amount of attraction you have towards a certain event.

In order to use arousal and valence, we have to express them in terms of music features.
For valence we can use harmony, mode and tonality.
For arousal we can use pitch, timbre, speed and loudness \cite{PresentationMER}\cite{PaperME}.

\newpage

The data of EEMCS does not explicitly provide the above features. However, we can extract some of them from the low-level features the data does provide.

The low-level features we can use for valence:
\begin{enumerate}
\item For harmony we can use the consonance and dissonance of a song.
\item To determine the mode of a song, we can use the key, key scale and key strength from the data.
The key strength also tells a bit about the tonality of the song.
When the key strength approaches 1, we can speak of tonality. When the key strength approaches 0, we can speak of atonality.
\end{enumerate}
The low-level features we can use for arousal:
\begin{enumerate}
\item Beats-per-minute (BPM) gives us the tempo of a song.
\item Loudness can be directly retrieved from the loudness feature.
\item Pitch can be direved from the tuning frequency, which is standardized at \SI{440}{\hertz} but may vary depending on music genre, era and geography.
\end{enumerate}

The timbre of a song is a separate research field and would be too difficult to integrate into our system.

%
% BIBLIOGRAPHY
%
\bibliography{productVision}{}
\bibliographystyle{plain}

\end{document}
